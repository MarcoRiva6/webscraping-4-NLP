{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf6943b72392a54",
   "metadata": {},
   "source": [
    "# Retrieve Reviews\n",
    "In this section the reviews from the two different sources are retrieved.\n",
    "\n",
    "The reviews are then stored in two different CSV files, one for each source."
   ]
  },
  {
   "cell_type": "code",
   "id": "3e3dd903a94bed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T16:32:46.811484Z",
     "start_time": "2024-12-25T16:32:45.882811Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "!pip install fast-langdetect --quiet\n",
    "from fast_langdetect import detect"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "71345e3dfe83bf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T16:32:46.815704Z",
     "start_time": "2024-12-25T16:32:46.813155Z"
    }
   },
   "source": [
    "# helper functions\n",
    "def hash_function(text):\n",
    "    return abs(hash(text)) % (10**8)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "3e9fbdb88bbae87f",
   "metadata": {},
   "source": [
    "## YELP\n",
    "Using APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T15:22:41.032374Z",
     "start_time": "2024-12-20T15:22:36.563861Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# API_KEY foir rapidapi\n",
    "API_KEY = \"10ccda3760msh06408370be84a12p114ca8jsnc974ddf5859c\"\n",
    "BASE_URL = \"https://red-flower-business-data.p.rapidapi.com\"\n",
    "SEARCH_URL = f\"{BASE_URL}/business-search\"\n",
    "REVIEWS_URL = f\"{BASE_URL}/business-reviews\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4497af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding rows to a file\n",
    "def add_to_file(file_path, fieldnames, data):\n",
    "  with open(file_path, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    for row in data:\n",
    "        filtered_row = {key: value for key, value in row.items() if key in fieldnames}\n",
    "        writer.writerow(filtered_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "553f7711bd0f623a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T15:22:41.038138Z",
     "start_time": "2024-12-20T15:22:41.034458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for fetching restaurants\n",
    "def get_yelp_restaurants(start=0):\n",
    "    headers = {\"X-RapidAPI-Key\": API_KEY, \"x-rapidapi-host\": \"red-flower-business-data.p.rapidapi.com\"}\n",
    "    params = {\n",
    "        \"query\": \"italian restaurant\",\n",
    "        \"location\": \"Rome, RM, Italy\",\n",
    "        \"yelp_domain\": \"yelp.com.tr\",\n",
    "        \"sort_by\": \"HIGHEST_RATED\",\n",
    "        \"start\": start \n",
    "    }\n",
    "\n",
    "    b_data = []\n",
    "    \n",
    "    response = requests.get(SEARCH_URL, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        businesses = data[\"data\"]\n",
    "        print(f\"Found {len(businesses)} businesses\")\n",
    "        for business in businesses:\n",
    "            b_data.append({\n",
    "                \"id\": business['id'],\n",
    "                \"name\": business['name'],\n",
    "                \"alias\": business[\"alias\"],\n",
    "                \"rating\": business[\"rating\"],\n",
    "                \"review_count\": business[\"review_count\"]\n",
    "            })\n",
    "            \n",
    "    return b_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daaf2967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: yelp_restaurants.csv\n",
      "File already exists: yelp_restaurants.csv\n",
      "File already exists: yelp_restaurants.csv\n",
      "File already exists: yelp_restaurants.csv\n",
      "File already exists: yelp_restaurants.csv\n",
      "File already exists: yelp_restaurants.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "file_path = \"yelp_restaurants.csv\"\n",
    "fieldnames = [\"id\",\"name\",\"alias\",\"rating\",\"review_count\"]\n",
    "\n",
    "# Fetching and saving restaurants\n",
    "for start in [0, 10, 20, 30, 40, 50]:\n",
    "    data = get_yelp_restaurants(start) ## The number passed is the start value: the api fetches 10 restaurants at time, with this number we say how many to skip so we can get more (like a pagination)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, mode='w', encoding='utf-8') as csvfile:\n",
    "            csvfile.write(\"id,name,alias,rating,review_count\\n\")\n",
    "            print(f\"File created\")\n",
    "    else:\n",
    "        print(f\"File already exists: {file_path}\")\n",
    "        \n",
    "    add_to_file(file_path, fieldnames, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6726c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function for taking saved data\n",
    "def load_restaurants_from_csv(file_path):\n",
    "    restaurants = []\n",
    "    try:\n",
    "        with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                restaurant = {\n",
    "                    'id': row['id'],\n",
    "                    'name': row['name'],\n",
    "                    'alias': row['alias'],\n",
    "                    'rating': float(row['rating']),\n",
    "                    'review_count': int(row['review_count'])\n",
    "                }\n",
    "                restaurants.append(restaurant)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing expected field {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: Data type conversion issue: {e}\")\n",
    "\n",
    "    return restaurants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35c8b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting reviews\n",
    "def get_yelp_reviews(restaurants):\n",
    "  output = []\n",
    "  headers = {\n",
    "      \"accept\": \"application/json\",\n",
    "      \"Authorization\": \"Bearer 3lX3EqE4bLsHCwaN8tyZ3kNNg_tykrIiw8cgEDcbNOeGYo9m22YYW5as-1dPp-f0Gy_X8_12CDEiqVgbM0SdKgKE2x94_w4-_PLu8Kfufdj-kBvbYWCGNmUUjyZHZ3Yx\"\n",
    "  }\n",
    "\n",
    "  for business in restaurants:\n",
    "    url = f\"https://api.yelp.com/v3/businesses/{business['id']}/reviews?limit=20&sort_by=yelp_sort\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "      data = response.json()\n",
    "      reviews = data['reviews']\n",
    "      if len(reviews) > 0:\n",
    "        for r in reviews:\n",
    "            if 'text' in r:\n",
    "              review_text = re.sub(r\"\\n\", \"\", r['text'].replace(\",\",\"\"))\n",
    "              new_data = {\n",
    "                  'review_id': r['id'], \n",
    "                  'restaurant_id': business['id'], \n",
    "                  'restaurant': business['name'], \n",
    "                  'text': review_text, \n",
    "                  'date': r['time_created']\n",
    "              }\n",
    "              output.append(new_data)\n",
    "                \n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a102cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'yelp_restaurants.csv'\n",
    "restaurants = load_restaurants_from_csv(file_path)\n",
    "restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a22c8bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: yelp_reviews.csv\n",
      "Getting data...\n",
      "Saving 0 reviews...\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Finally getting and saving reviews\n",
    "\n",
    "file_path = \"yelp_reviews.csv\"\n",
    "fieldnames = [\"review_id\", \"restaurant_id\", \"restaurant\", \"text\", \"date\"]\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with open(file_path, mode='w', encoding='utf-8') as csvfile:\n",
    "       csvfile.write(\"review_id,restaurant_id,restaurant,text,date\\n\")\n",
    "    print(f\"File created\")\n",
    "else:\n",
    "    print(f\"File already exists: {file_path}\")\n",
    "\n",
    "print(\"Getting data...\")\n",
    "\n",
    "reviews = get_yelp_reviews(restaurants)\n",
    "\n",
    "print(f\"Saving {len(reviews)} reviews...\")\n",
    "add_to_file(file_path, fieldnames, reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da5d51d739a0bb",
   "metadata": {},
   "source": [
    "## OpenTable\n",
    "Using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e2db99e3839c2",
   "metadata": {},
   "source": [
    "### Define scrapping functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "922cda24fb977608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T16:32:07.607103Z",
     "start_time": "2024-12-25T16:32:07.595050Z"
    }
   },
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# needed so to have the lists (restaurants and reviews) loaded from the website\n",
    "def scroll_down_page(driver, speed=8):\n",
    "    current_scroll_position, new_height= 0, 1\n",
    "    while current_scroll_position <= new_height:\n",
    "        current_scroll_position += speed\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(current_scroll_position))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "# obtain the list of restaurants based on the predefined criteria\n",
    "def scrape_opentable_restaurants(keep_open=False, max_restaurants=10):\n",
    "    # queries OpenTable restaurants in 'Paris' under 'Italian' cousine category, ordered by rating\n",
    "    url = \"https://www.opentable.com/s?term=paris&cuisineIds%5B%5D=48e9d049-40cf-4cb9-98d9-8c47d0d58986&sortBy=rating\"\n",
    "\n",
    "    # open the browser\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    # scroll down the page so to have all the restaurants loaded\n",
    "    scroll_down_page(driver)\n",
    "    time.sleep(3)\n",
    "\n",
    "    restaurants = []\n",
    "\n",
    "    try:\n",
    "        # Extract restaurant elements\n",
    "        restaurant_elements = driver.find_elements(By.CLASS_NAME, 'qCITanV81-Y-')\n",
    "        restaurant_counter = 0\n",
    "        for restaurant_element in restaurant_elements:\n",
    "            try:\n",
    "                restaurant_name = restaurant_element.text # name\n",
    "                restaurant_link = restaurant_element.get_attribute('href') # link\n",
    "                restaurant_link = restaurant_link[:-122] # remove parameters\n",
    "                restaurants.append({'restaurant_name': restaurant_name, 'restaurant_link': restaurant_link})\n",
    "                restaurant_counter += 1\n",
    "                if max_restaurants != 0 and restaurant_counter >= max_restaurants:\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting restaurants: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scraping: {e}\")\n",
    "    finally:\n",
    "        if not keep_open:\n",
    "            driver.quit()\n",
    "\n",
    "    return restaurants, driver\n",
    "\n",
    "# scrape reviews from the given restaurant\n",
    "def scrape_opentable_reviews(driver, url, keep_open=False, max_reviews=10):\n",
    "\n",
    "    # open the browser if not already open\n",
    "    if driver is None:\n",
    "        driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    reviews = []\n",
    "\n",
    "    try:\n",
    "        # scroll down the page so to have all the reviews loaded\n",
    "        scroll_down_page(driver)\n",
    "        time.sleep(1)\n",
    "        # Extract review elements\n",
    "        review_elements = driver.find_elements(By.CLASS_NAME, 'afkKaa-4T28-')\n",
    "        review_counter = 0\n",
    "\n",
    "        for review_element in review_elements:\n",
    "            try:\n",
    "                review_text = review_element.find_element(By.CLASS_NAME, '_6rFG6U7PA6M-').text # review text\n",
    "                review_date = review_element.find_element(By.CLASS_NAME, 'iLkEeQbexGs-').text # review date\n",
    "                reviews.append({'review_text': review_text, 'review_date': review_date})\n",
    "                \n",
    "                review_counter += 1\n",
    "                if max_reviews != 0 and review_counter >= max_reviews:\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting review: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scraping: {e}\")\n",
    "    finally:\n",
    "        if not keep_open:\n",
    "            driver.quit()\n",
    "\n",
    "    return reviews\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "864598f42fe4bf07",
   "metadata": {},
   "source": [
    "### Get reviews"
   ]
  },
  {
   "cell_type": "code",
   "id": "6402e37148c3a14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T16:34:42.605718Z",
     "start_time": "2024-12-25T16:34:42.587848Z"
    }
   },
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def get_opentable_reviews(output_csv, max_restaurants=30, max_reviews=10):\n",
    "    \"\"\"\n",
    "    retrieves reviews from OpenTable.\n",
    "    :return: A list of reviews, each being: {'review_id', 'restaurant_id', 'restaurant', 'text', 'date'}\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_restaurants_already_scraped = set()\n",
    "    if os.path.exists(output_csv):\n",
    "        try:\n",
    "            with open(output_csv, mode='r', encoding='utf-8') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "    \n",
    "                for row in reader:\n",
    "                    restaurant_name = row.get('restaurant_id', '').strip()\n",
    "                    unique_restaurants_already_scraped.add(restaurant_name)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "            return []\n",
    "\n",
    "    result = []\n",
    "\n",
    "    if len(unique_restaurants_already_scraped) >= max_restaurants:\n",
    "        try:\n",
    "            with open(output_csv, mode='r', encoding='utf-8') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "\n",
    "                for row in reader:\n",
    "                    review = {\n",
    "                        'review_id': row.get('review_id', '').strip(),\n",
    "                        'restaurant_id': row.get('restaurant_id', '').strip(),\n",
    "                        'restaurant': row.get('restaurant', '').strip(),\n",
    "                        'text': row.get('text', '').strip(),\n",
    "                        'date': row.get('date', '').strip(),\n",
    "                    }\n",
    "                    result.append(review)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "            return []\n",
    "\n",
    "        return result\n",
    "\n",
    "    # scrape restaurants\n",
    "    restaurants, driver = scrape_opentable_restaurants(True, max_restaurants)\n",
    "\n",
    "    # scrape reviews\n",
    "    for n, restaurant in enumerate(restaurants):\n",
    "        if restaurant['restaurant_name'] in unique_restaurants_already_scraped:\n",
    "            continue\n",
    "        reviews = scrape_opentable_reviews(driver, restaurant['restaurant_link'], True if n < len(restaurants) else False, max_reviews)\n",
    "        for review in reviews:\n",
    "            result.append({\n",
    "                'review_id': hash_function(f\"{restaurant['restaurant_name']}{review['review_text']}\"),\n",
    "                'restaurant_id': hash_function(restaurant['restaurant_name']),\n",
    "                'restaurant': restaurant['restaurant_name'],\n",
    "                'text': review['review_text'],\n",
    "                'date': review['review_date']\n",
    "            })\n",
    "\n",
    "    # save the results to a CSV file\n",
    "    with open(output_csv, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['review_id', 'restaurant_id', 'restaurant', 'text', 'date'])\n",
    "        if file.tell() == 0:  # Check if the file is empty to write the header\n",
    "            writer.writeheader()\n",
    "        writer.writerows(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "get_opentable_reviews(\"opentable_reviews.csv\")\n",
    "\n",
    "opentable_reviews = pd.read_csv(\"opentable_reviews.csv\")\n",
    "opentable_reviews.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   review_id  restaurant_id     restaurant  \\\n",
       "0   45775551       73093209  Restaurant Zo   \n",
       "1   43409730       73093209  Restaurant Zo   \n",
       "2   39410757       73093209  Restaurant Zo   \n",
       "3   32270298       73093209  Restaurant Zo   \n",
       "4   44992094       73093209  Restaurant Zo   \n",
       "\n",
       "                                                text                      date  \n",
       "0  Being from out of town, it’s always worrisome ...          Dined 7 days ago  \n",
       "1  the restaurant Zo was close, and it was far aw...  Dined on August 16, 2024  \n",
       "2  Amazing dinner with friends. Food was deliciou...   Dined on August 2, 2024  \n",
       "3  Dined on Thursday evening with group of 9 coll...   Dined on April 18, 2024  \n",
       "4  Great food and staff was very friendly.  Fun p...    Dined on April 5, 2024  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45775551</td>\n",
       "      <td>73093209</td>\n",
       "      <td>Restaurant Zo</td>\n",
       "      <td>Being from out of town, it’s always worrisome ...</td>\n",
       "      <td>Dined 7 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43409730</td>\n",
       "      <td>73093209</td>\n",
       "      <td>Restaurant Zo</td>\n",
       "      <td>the restaurant Zo was close, and it was far aw...</td>\n",
       "      <td>Dined on August 16, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39410757</td>\n",
       "      <td>73093209</td>\n",
       "      <td>Restaurant Zo</td>\n",
       "      <td>Amazing dinner with friends. Food was deliciou...</td>\n",
       "      <td>Dined on August 2, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32270298</td>\n",
       "      <td>73093209</td>\n",
       "      <td>Restaurant Zo</td>\n",
       "      <td>Dined on Thursday evening with group of 9 coll...</td>\n",
       "      <td>Dined on April 18, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44992094</td>\n",
       "      <td>73093209</td>\n",
       "      <td>Restaurant Zo</td>\n",
       "      <td>Great food and staff was very friendly.  Fun p...</td>\n",
       "      <td>Dined on April 5, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "c8d3603bc5ecc65c",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "This section is dedicated to the preprocessing of the data retrieved from the two sources.\n",
    "\n",
    "The foreign characters from the reviews' text are removed and each of the entry is annotated with its language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106dad685a134073",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c71df651fc12772c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T12:22:35.578732Z",
     "start_time": "2024-12-25T12:22:35.559114Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the text by removing non-text characters while retaining accented characters.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The input text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    - str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Keep Unicode letters, digits, spaces, and basic punctuation\n",
    "    return re.sub(r'Read more$', '', re.sub(r'[^\\w\\s.,!?\\'\\\"-]', '', text.replace(\"\\n\", \"\"), flags=re.UNICODE), flags=re.UNICODE)\n",
    "\n",
    "def clean_reviews(df):\n",
    "    df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "opentable_reviews = pd.read_csv(\"opentable_reviews.csv\")\n",
    "yelp_reviews = pd.read_csv(\"yelp_reviews.csv\")\n",
    "clean_reviews(opentable_reviews)\n",
    "clean_reviews(yelp_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c50bcd5c0dc893",
   "metadata": {},
   "source": [
    "## Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "509c4216f232550f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T12:26:39.340999Z",
     "start_time": "2024-12-25T12:26:39.173735Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text.replace(\"\\n\", \"\"), low_memory=False)[\"lang\"]\n",
    "    except Exception:\n",
    "        return 'unknown'\n",
    "\n",
    "def annotate_language(df):\n",
    "    df['language'] = df['text'].apply(detect_language)\n",
    "\n",
    "annotate_language(opentable_reviews)\n",
    "annotate_language(yelp_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6928e0feb5840254",
   "metadata": {},
   "source": [
    "## Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6769f523ea0f22a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T12:28:36.186196Z",
     "start_time": "2024-12-25T12:28:36.140184Z"
    }
   },
   "outputs": [],
   "source": [
    "opentable_reviews.to_csv(\"opentable_reviews_cleaned.csv\", index=False)\n",
    "yelp_reviews.to_csv(\"yelp_reviews_cleaned.csv\", index=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "opentable_reviews.head()",
   "id": "3a9a31ec0bf4796c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "yelp_reviews.head()",
   "id": "a29a4775fd3a74ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
